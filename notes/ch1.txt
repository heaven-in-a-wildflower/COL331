* The linear memory model abstraction allows the programmer to write code easily and the compiler to generate the assembly code easily.
* In segmented memory model, VA space is partitioned into multiple segments, each start address being stored in a hardware register.
* Privileged registers allow the OS to interact with the hardware
* L1 cache size is generally 8-64KB
* LLC - last level cache
* OS is unaware of cache hierarchy
* registers - named storage locations that are directly accessible by instructions and can be accessed in a fraction of a cycle.
* RISC ISAs - simple and regular decoder, easy to generate code. CISC ISAs allow more complex instructions(longer immediates, multiple memory operands) to be stored in fewer bits.
* Hypervisors and VMMs run with OS level privilges and can access privileged registers.
* Privilege registers -
	a. flags registers - stored comparison result of ALU, necessary for context switching
	b. Control registers - enable/disable specific hardware features
	c. Debug registers - security concern regarding access to program state
	d. I/O registers
* Polymorphic instructions(diff meanings for diff privilege levels) in many ISAs either remains silent or yield different behaviour in different priv modes  - huge security concern - because VMs were not prevalent when ISAs were being designed.

* Interrupt - Generated by an I/O device or controller. Stop execution of current program and jump to address of interrupt handler.
* Exception - Error in program execution
* Syscall - Dummy interrupt generated by a process to get OS's attention - invokes syscall handler.
* Signal - A callback function an application registers with the OS. On an event of interest, OS calls the signal handler.

** Traditional methods like shared memory or function invocation cannot be used to invoke OS because it runs in a separate address space. Also, switching to kernel mode is a time-consuming activity requiring both HW and SW intervention.


Syscalls
=======
* It is not advised to directly issue syscalls since one may not be aware of its full semantics. Also, OSs tend to change syscall signatures over time. Instead recommended to use wrapper functions for them(such as glibc), since these are designed to be very flexible and thus almost never change signature - thus portable across OSs.

* syscall no. loaded into %rax and then issued.

* program_state = (PC + register states(GPR,flags,other special registers))(volatile) + memory(done by the virt mem system)
Need for specialised hardware instructions to store the volatile state in specialised registers or memory(GPR dumped to memory), sometimes sp is also stored.

* OS never executes in the background - programmable timer chip to generate periodic interrupts at every jiffy(1ms, can be changed with compile time parameter HZ). Do not want jiffy to be too long(for responsiveness) or too short(increased overhead.)

* If a process has to be run on a diff core than the one the OS is currently running on, then the OS first sends a IPI(inter processor interrupt) to that core so that first an OS process starts running on it.

Virt Mem
=======
* The programmer, compiler, and a large part of the CPU pipeline views memory as one large array of bytes.

* Size of register directly linked to size of addressable memory

* Compatibility problem(How to run a program which assumes access to the entire 2^n byte array on a machine different from the one it was compiled on, especially ones with very small memories)

* Overlap problem

* Size problem(memory footprint of the program exceeds the system's main memory size) - backward compatibilty compromised??(p37)

Mem Map
-------
* text,data,bss,heap,stack.
* Top portion of virtual mem space of a reserved for OS(1GB out of 4Gb in 32-bit systems)(invariant across processes)
* Fixed mem layout makes it easy to generate code, binaries can have a fixed data format.
* Overlap problem worsened by fixed mem layout

* base & limit register approach - does not require programmer or compiler to know the exact values but the difference. Problem - neither the programmer nor the compiler knows runtime memory req, will need to estimate a conservative maximum(may end up wasting memory) - internal fragmentation.

* External fragmentation - multiple holes between allocated regions which are too small to allocate memory for a process(even though sum of memory contained in holes may be sufficiently large). Problem with periodically combining holes is that it needs a lot of reads and writes during which other processes will have to remian stalled.

* Mapping a virtual address to a single physical address solves the compatibilty problems. Mapping every physical address to a single virtual address solves the overlap problem. Size problem solved if we include storage devices to supplement main memory.

* Mapping addresses at a larger granularity(page size) allows for less bookkeeping, takes advantage of temporal and spacial loclity.

* 4KB page suits needs of most systems, may be from 2MB to 1GB in case of servers. Size of page=size of frame it is mapped to.

* Multilevel page table needed to reduce mem req to store page table(4KB page = 12 bits => 2^20 bits to store the physical frame addresses per process(2.5MB), for 100 processes = 250MB => prohibitive).

* Most of the VA space is not used(massive hole between heap and stack-sometimes used by DLLs and memory mapped regions).

* 48 bit VA(includes the 12 bits per page) is sufficient for most systems. Divide rem 36 bits into 4 halves for a 4 level page table. Entry in l1 page table is either null or points to l2 page table entry. Most entries are expected to be null since memory map is sparse and the top 9 bits correspond to a large contiguous memory region, this allows us to save space. Sim, for l2,l3 page tables. Entry in l4 table stores physical address.

* Whenever a process is loaded, its l1 page table address is loaded into c3 register

* Walking the page table is a slow process, upto 1000 cycles in worst case. About 1/3rd of all instructions are memory accesses.

* Page table has more locality than cache block due to larger size. With just 64-128 entries, TLB can have a 99% hit rate.

* Modern TLBs have two levels, store about 1000 entries. L1 TLB is small and can be accessed in less than a cycle. This latency is hidden away in OOO processors.

* Page table is a software data structure. Page table walking is done by the OS or a dedicated hardware module(for high perf).

* Page can either be in phys memory or swap space, in latter case, it needs to be brought into main memory to be usable.

* TLB hit - l1,l2,main mem(guaranteed to exist in..), TLB miss - walk the page table. If found in main mem, need to add it to TLB first(modern processors cannot directly use this mapping, they need to add it to TLB first and then reissue instruction). If not found in page table, but exists in swap space: page fault -> need to update TLB and page table entries for the new page as well as for the page being evicted if any.

* Can have multiple swap spaces - some bits to indicate the swap device, one bit to check if entry is present.

Permission bits
---------------
* A program is not allowed to write code pages. This would allow viruses to modify code page to execute malicious code.
* Can have r,w,x bits associated with a code page - set in both page table and TLB. One bit to check if user level process can it.
* If page is present in mem, but user process does not have permission to access it - soft page fault - generates exception.
* Multi-generational LRU eviction scheme deliberately induces soft page faults to gauge the populatity of a page.
* Linux std clib supports shmget(create shared mem segment) and shmat(attach shared mem segment).

Inverted Page table
-------------------
* (In case of shared mem)If a frame is to be removed from main mem, need to update page tables of all processes that have a mapping to it. Sim, if we need to change the permission bits of a frame.
* Since number of physical pages is much less than virtual pages, we can reduces space requirement at the cost of latency(IPTs rely on linked list chaining, hash collisions can increase latency of an access).

Segmented memory
----------------
* When virtual memory concept was not discovered, and base-limit addressing was used, segment registers used to act as base registers for code, data and stack. Code and data used to be stored in separate physical segments, sometimes even on separate storage devices.

* New use case - Can prohibit a process from accessing a code page i.e it is not possible for a data access to modify the region of memory that stores code(instructions) - since data segment is located above the code segment.

* For the set of attacks that modify the return address of a call, they need to know the memory address at which the ra reg is stored. The OS can randomly set the contents of ssr in each run - obfuscation. The attacker is unable to guess what is stored in a given address at each run.

* Can use a specific seg reg as base reg for per core regions(for memory management and scheduling) for kernel processes.

* Need to explot temporal and spacial locality as much as possible for addressing segmented mem -> use SDC : caches the ids of seg regs for the current process. These contents will change only when the process is loaded for the first time or a context switch i.e even more infrequently than a TLB. In case of SDC miss, look for id in the GDT(a hardware structure). All segment ref related data is actually stored in a separate data structure which needs to be accessed in case of a GDT miss.

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Data structures
#define offsetof(st, m) \
    ((size_t)&(((st *)0)->m))

* Macros are executed by the preprocessor which is aware of the code and the layout of the structures used.

static inline void hlist_del(struct hlist_node *n)
{
    if (!n->pprev)  // If pprev is NULL, the node is not in a list
        return;

    if (n->next)
        n->next->pprev = n->pprev;

    *n->pprev = n->next; // Update the previous node's 'next' pointer

    n->next = NULL;
    n->pprev = NULL; // Clear pprev to indicate node is removed
}

This method allows us to delete a node in a linked list while traversing using a single pointer instead if the traditional two pointer approach using prev and curr, thereby saving instructions.

* AVL trees are intended for in-memory use, where random access is relatively cheap. B-trees are better suited for disk-backed storage, because they group a larger number of keys into each node to minimize the number of seeks required by a read or write operation. (This is why B-trees are often used in file systems and databases). RB trees require less rebalancing than AVL trees(theoretically both support O(logn) insertions and deletions).
